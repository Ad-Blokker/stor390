---
title: "Harry Potter and regular expressions"
author: 'STOR 390'
output: html_document
---

Assignment 2 is due 2/28/17.

The text of all 7 Harry Potter books is available online: [http://www.readfreeonline.net/Author/J._K._Rowling/Index.html](http://www.readfreeonline.net/Author/J._K._Rowling/Index.html). In this assignment you will use dplyr, ggplot and regular expressions to do an exploratory analysis of Harry Potter and the Philosopher's Stone.

Here are a couple examples of similar text analysis projects (that you will be able to do in a couple weeks!)

- [The Life-Changing Magic of Tidying Text](http://juliasilge.com/blog/Life-Changing-Magic/) by Julia Silge (yes [janeaustenr](https://github.com/juliasilge/janeaustenr) is an entire R package devoted to Jane Austen)

- [Harry Potter agression](https://github.com/andrewheiss/Harry-Potter-aggression) by Andrew Heiss

# Grading key

## Points per question
Total: 100 pts

1. 3

2. 10

3. 7

4. 13

5. 7

6. 10

7. 7

8. 10

9. 3

10. 7

11. 7

12. 3

13 (free response). 13

## Deductions

1. -3 for not having a reasonable solution. Depending on how you code a 'word' in regular expressions, you can get different answers.

2. -5 for incorrect or missing output statistics. 'Visualization' is vague, so a labeled table was fine. 

3. -4 incorrect output but reasonable attempt

4. Sliding scale of deductions based on function quality. If your function can do all three split types in an effective way, you will get full credit. It doesn't need work for every single idiosyncratic issue in the text. You can get minor points off for functions that clearly leave out some potentially useful information, for example if you extracted sentences but the regular expression clearly didn't extract any punctuation within them. 

5. -4 for creating a data frame or tibble that doesn't have one row per paragraph. -3 for not having a Harry column.

6. -5 for incorrect function output. Sliding scale for function quality after that.

7. -3 for updating the data frame but with incorrect information

8. -4 each for missing a graph, -2 for missing or insufficient written response.

9. -1 each for missing a graph or a written explanaton, or for producing incorrect graphs: e.g. not plotting harry mentions on one axis and hermione mentions on the other

10. -3 for missing the linear regression, -4 for missing the plot

11. -2 for missing the regression, -1 for not answering the question, -4 for missing the plot.

12. -3 incorrect result

13 (free response). -4 each for missing a figure, up to -5 for insufficient or missing written explanation and supporting evidence

## Additional deductions

- -7 if at least one of your markdown documents failed to knit.

- -1 for grammatical or other written communications errors, such as poor or unclear syntax and dangling modifiers.

- -2 each for having at least one illegible axis or legend in a plot, for indecipherable plot output (such as white on white plotting), or for failing to include axis labels or plot legends altogether.

# Load the data
The `rvest` package makes scraping websites easy with R. The following code will download the text of the Harry Potter and the Philosopher's Stone from readfreeonline and save it as a string (called `text`). I suggest running this code once then saving text on your computer and using `read_lines` to read the text file into your computer.

```{r, eval=F}
library(tidyverse)
library(rvest)


chapter_base_url <- 'http://www.readfreeonline.net/OnlineBooks/Harry_Potter_and_the_Sorcerers_Stone/Harry_Potter_and_the_Sorcerers_Stone_'
num_chapters <- 17

# download each chapter and concatonate them
text <- ''
for(i in 1:num_chapters){
    
    # url for the chapter text
    chapter_url <- paste0(chapter_base_url, i, '.html')
    
    # download the chatpter html
    chapter_html <- read_html(chapter_url)  
    
    # extract the text of the chatper from the html
    chapter_text <- chapter_html %>%
                html_nodes(".ContentCss") %>%
                html_text()
    
    #
    text <- paste0(text, chapter_text)
}

# save as a .txt file
# write_lines(text, 'philosophers_stone.txt')
```


# Question 0
Set `eval=FALSE` for the chunck above and `eval=TRUE`for the chunck below and all test chunks.
```{r, eval=TRUE, message=F, warning=F}
# set up
library(tidyverse)
library(stringr)
text <- read_file('philosophers_stone.txt')
```

# Question 1
How many words are in the book? 

```{r}
# You can see a 'word' as anything between consecutive spaces
length(str_split(text, '\\s+', simplify = T))

# Or you can use the word regular expression (which counts words split by apostrophes as separate)
str_count(text, "\\w+")

# Or you can account for apostrophes
str_count(text, "[\\w']+")

```


# Question 2 

How many times are each of the following characters mentioned? Display the answer using an appropriate visualization. 

    - Harry, Hermione, Ron, Neville, Dumbledore, Draco, Snape, Hagrid, McGonagall


*Hint*: the `map` function might be helpful (but not necessary).


```{r}
people <- c('Harry', 'Hermione', 'Ron', 'Neville', 'Dumbledore', 'Draco', 'Snape', 'Hagrid', 'McGonagall')

# count the number of times each person is references
mentions <- str_count(text, people)

# create a data frame
character_refs <- tibble(person=people, mentions=mentions) %>%
                    arrange(person)

# horizontal > vertical bars for string categories
ggplot(data=character_refs)+
    geom_bar(aes(person, mentions), stat='identity') +
    coord_flip()
```






# Question 3
Break the text into paragraphs; create a verctor called `paragraphs` where each entry is a paragraph in the book.


```{r}
# paragraphs end with \\\r\\\n
paragraphs <- str_split(text, '\\\r\\\n', simplify = TRUE)
```


# Question 4
Write a function that can break the text up into paragraphs, sentences, or words. This is a preview of [what you'll be doing](http://tidytextmining.com/tidytext.html#the-unnest_tokens-function) in a couple weeks.

This function does not need to be perfect. For sentences, give one example where the function you wrote fails.

*Hint*: the function should probably have a if statement
```{r}

unnest_tokens <- function(text, token='words'){
  # splits a string into tokens
  # input
  # text is a string
  # token can be one of: words, paragraphs, sentences
  # output: a character vector
  
  
  if(token=='words'){
    # here words with apostrophes to appear as a single word, hyphenated words to appear as two
    tokens <- str_extract_all(text, "[\\w']+", simplify = TRUE)
  } else if(token=='sentences'){
    tokens <- str_split(text, boundary("sentence"), simplify = TRUE)
  } else if(token=='paragraphs'){
    tokens <- str_split(text, '\\\r\\\n', simplify = TRUE)
  }else{
    print('problem with token argument')
  }
  tokens
}

```


```{r test4, eval=T}
sum(paragraphs == unnest_tokens(text, 'paragraphs'))
```


# Question 5

Put the data into tidy format with one row per paragraph. 

- first remove all paragraphs length 0
- create a tibble called `paragraph_df` with one column `text` with the text of each paragraph (*hint*: you might need to use `as.character(paragraphs)`)
- add a new column `index` that gives the index of each paragraph
- **wighout** using dplyr add a column called `Harry` that counts the number of times Harry is referenced in each paragraph


```{r}
# remove paragraphs length 0
paragraphs <- paragraphs[str_length(paragraphs) > 0]

# create tibble
paragraph_df <- tibble(text=as.character(paragraphs))
paragraph_df <- paragraph_df %>% add_column(index=1:dim(paragraph_df)[1])
paragraph_df['Harry'] <- str_count(paragraph_df$text, 'Harry')
```

*Hint*: you can use question 2 to check your answer

# Question 6
Write a function called `reference_counter` that generalizes question 5 for any tidy text data frame and any list of words. 

*Hint*: do this **without** dplyr

```{r}

reference_counter <- function(text_df, word_list){
    
    # inputs
        # text_df is a tibble with a column called text
        # word_list is a vector of strings
    # for each word in word_list add a column to text_df counting
    # the number of times that word appears in each row of text df
    # does not modify the original text_df
    # do this WITHOUT using dplyr
    
    for(s in word_list){
        text_df[s] <- str_count(text_df$text, s)
    }
    text_df
}
```


```{r test6, eval=T}
test_words <- c('Harry', 'Hagrid', 'wand')
test_df <- reference_counter(paragraph_df, test_words)

test_df %>% select(Harry, Hagrid, wand) %>% summarise_all(sum)
```



# Question 7 

Using the `reference_counter` function update `paragraph_df` to include columns counting the number of references to each characters from Q2 in each paragraph


```{r}
paragraph_df <- reference_counter(paragraph_df, people)
```



```{r test7, eval=T}
head(paragraph_df)
paragraph_df[,people] %>% summarise_all(sum)
```


# Question 8

Make a new data frame called `person_refs`  with three columns: person, num_refs, index. num_refs is the number of references each person gets in paragraph and index is the index of the paragraph. Limit this data frame to the following 5 characteres: Harry, Hermione, Ron, Draco, Neville. 

*Hint*: use `gather`.

```{r}
person_refs <- paragraph_df %>% 
    select(index, Harry, Hermione, Ron, Draco, Neville) %>%
    gather(key=person, value=num_refs, Harry, Hermione, Ron, Draco, Neville)
```


Make a bar plot showing the number of paragraphs that references each of the 5 characters

```{r}
ggplot(person_refs) +
    geom_bar(aes(x=person, y=num_refs), stat='identity')
```


Now we want to examine how characters evolove over "time." Plot the number of references vs. the paragraph index.

```{r}
ggplot(person_refs) +
    geom_point(aes(x=index, y=num_refs, color=person)) + 
    geom_line(aes(x=index, y=num_refs, color=person)) 
```

In this question we are using paragraphs for "time windows." What are other "time windows" we could have used? What are some tradeoffs for these different choices.

# Question 9
How often are Harry and Herminone referenced together? Plot the number of references per paragraph for Harry vs. Herminone.

- one plot using `geom_point`
- one plot using `geom_jitter` (usethe width/height arguments of jitter to make the jitter plot look better)


```{r}
paragraph_df %>%
    ggplot() +
    geom_point(aes(x=Harry, y=Hermione))
```


```{r}
paragraph_df %>%
    ggplot() +
    geom_jitter(aes(x=Harry, y=Hermione), width = .1, height = .1)
```


Why is the jitter plot better than a simple point plot?


# Question 10
Do Harry and Hermione tend to co-occur?  Fit a linear regression of Harry vs. Hermione references per paragraph. Use the `lm()` function and print out the `summary` of the model.


```{r}
lin_reg <- lm(Harry ~ Hermione, paragraph_df)
summary(lin_reg)
```


Now use `geom_smooth` to plot the linear regression line on top of the jitter plot.

```{r}
paragraph_df %>%
    ggplot() +
    geom_jitter(aes(x=Harry, y=Hermione), width = .1, height = .1) + 
    geom_smooth(aes(x=Harry, y=Hermione), method=lm,se=FALSE)
```


# Question 11
Is there are relationship between the length of the pargraph a the number of times Harry is mentioned? Add a column called `num_words` to `paragraph_df` counting the number of words in each paragraph. Then use a linear regression to answer for the question. Provide both a statistical summary and a visualization.


```{r}
paragraph_df <- paragraph_df %>% mutate(num_words = str_count(text, "[\\w']+") + 1)

lin_reg <- lm(num_words ~ Harry, paragraph_df)
summary(lin_reg)
                            
                    
paragraph_df %>%
    ggplot() +
    geom_jitter(aes(x=num_words, y=Harry), width = 0, height = .1) + 
    geom_smooth(aes(x=num_words, y=Harry), method=lm,se=FALSE)   
```

# Question 12
Create an indeicator variable `harry_mentioned` that indicates whether or not Harry is mentioned in each paragraph. This indicator variable should be a factor (e.g. use `as.factor`).

```{r}
paragraph_df <- paragraph_df %>% mutate(harry_mentioned = as.factor(Harry > 0))

```

Now repeate the previous linear regression with `harry_mentioned` as the x variable instead of the number of times he is mentioned

```{r}
lin_reg <- lm(num_words ~ harry_mentioned, paragraph_df)
summary(lin_reg)
```


# Free response
Ask and answer a question with this data set. You should make at least 2 figures (e.g. plot, printout of a regression, etc). Provide a written explaination of the question and the evidence for your answer.









